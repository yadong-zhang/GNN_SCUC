{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read grid info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create buses\n",
    "num_buses = 118\n",
    "buses = np.arange(1, num_buses+1)\n",
    "\n",
    "# Read gen buses\n",
    "file_path = '../../data/IEEE_Case118/zones/gen_bus.csv'\n",
    "gen_buses = pd.read_csv(file_path, header=None, index_col=None)\n",
    "\n",
    "# Read thermal buses\n",
    "file_path = '../../data/IEEE_Case118/zones/thermal_bus.csv'\n",
    "thermal_buses = pd.read_csv(file_path, header=None, index_col=None)\n",
    "\n",
    "# Read wind gen buses\n",
    "file_path = '../../data/IEEE_Case118/zones/wind_bus.csv'\n",
    "wind_buses = pd.read_csv(file_path, header=None, index_col=None)\n",
    "\n",
    "# Read load buses\n",
    "file_path = '../../data/IEEE_Case118/zones/load_bus.csv'\n",
    "load_buses = pd.read_csv(file_path, header=None, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean index of thermal buses\n",
    "thermal_bidx = np.isin(buses, thermal_buses)\n",
    "\n",
    "# Boolean index of wind buses\n",
    "wind_bidx = np.isin(buses, wind_buses)\n",
    "\n",
    "# Boolean index of load buses\n",
    "load_bidx = np.isin(buses, load_buses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get thermal gen features (To be determined)\n",
    "Pmax = pd.read_csv('../../data/IEEE_Case118/gen_params/Pmax.csv',\n",
    "                   header=None,\n",
    "                   index_col=None)\n",
    "Pmin = pd.read_csv('../../data/IEEE_Case118/gen_params/Pmin.csv',\n",
    "                   header=None,\n",
    "                   index_col=None)\n",
    "ramp_30 = pd.read_csv('../../data/IEEE_Case118/gen_params/ramp_30.csv',\n",
    "                      header=None,\n",
    "                      index_col=None)\n",
    "startup_cost = pd.read_csv('../../data/IEEE_Case118/gen_params/startup_cost.csv',\n",
    "                            header=None,\n",
    "                            index_col=None)\n",
    "shutdown_cost = pd.read_csv('../../data/IEEE_Case118/gen_params/shutdown_cost.csv',\n",
    "                            header=None,\n",
    "                            index_col=None)\n",
    "gencost_params = pd.read_csv('../../data/IEEE_Case118/gen_params/gencost_params.csv',\n",
    "                                header=None,\n",
    "                                index_col=None)\n",
    "reserve_qty = pd.read_csv('../../data/IEEE_Case118/gen_params/reserve_qty.csv',\n",
    "                            header=None,\n",
    "                            index_col=None)\n",
    "reserve_cost = pd.read_csv('../../data/IEEE_Case118/gen_params/reserve_cost.csv',\n",
    "                            header=None,\n",
    "                            index_col=None)\n",
    "\n",
    "# Get the Boolean idx of thermals in gens\n",
    "bidx = np.isin(gen_buses, thermal_buses).reshape((-1))\n",
    "\n",
    "temp = np.concatenate([Pmax, Pmin, ramp_30, startup_cost, \n",
    "                  shutdown_cost, gencost_params], axis=1)\n",
    "\n",
    "# Create thermal gens features\n",
    "thermal_gen_features = np.concatenate([temp[bidx], reserve_qty, reserve_cost], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time steps\n",
    "nt = 12\n",
    "\n",
    "# Read wind and load inputs into MATPOWER\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MATPOWER UC solution\n",
    "y_DL = []\n",
    "\n",
    "# Add zeros to make the dimension as [num_buses, nt]\n",
    "all_DL = np.zeros((num_buses, nt))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    DL_path = f'../../data/IEEE_Case118/outputs/deployed_load/sample_{i+1}.csv'\n",
    "    try:\n",
    "        DL = pd.read_csv(DL_path, header=None, index_col=None).to_numpy()\n",
    "    except FileNotFoundError:\n",
    "        print(f'The file sample_{i+1} is not found')\n",
    "        continue\n",
    "\n",
    "    all_DL[load_bidx] = DL\n",
    "\n",
    "    y_DL.append(all_DL.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge index and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read branch info\n",
    "file_path = '../../data/IEEE_Case118/branch_params/branch_params.csv'\n",
    "branch = pd.read_csv(file_path, header=None, index_col=None).to_numpy()\n",
    "\n",
    "# Read and assign PF_max\n",
    "RATE_A = 5                  # Index of RATE_A\n",
    "########################## These numbers are determined separately ##############################\n",
    "file_path = f'../../data/IEEE_Case118/branch_params/PF_max_category1.csv'\n",
    "PF_max_category1 = pd.read_csv(file_path, header=None, index_col=None).to_numpy().astype(bool).flatten()\n",
    "file_path = f'../../data/IEEE_Case118/branch_params/PF_max_category2.csv'\n",
    "PF_max_category2 = pd.read_csv(file_path, header=None, index_col=None).to_numpy().astype(bool).flatten()\n",
    "file_path = f'../../data/IEEE_Case118/branch_params/PF_max_category3.csv'\n",
    "PF_max_category3 = pd.read_csv(file_path, header=None, index_col=None).to_numpy().astype(bool).flatten()\n",
    "PF_max1 = 200\n",
    "PF_max2 = 200\n",
    "PF_max3 = 200\n",
    "branch[PF_max_category1, RATE_A] = PF_max1\n",
    "branch[PF_max_category2, RATE_A] = PF_max2\n",
    "branch[PF_max_category3, RATE_A] = PF_max3\n",
    "\n",
    "# Get branch index and attr\n",
    "edge_index = branch[:, :2] - 1\n",
    "edge_attr = branch[:, 2:]\n",
    "\n",
    "# Convert to standard format\n",
    "edge_index = torch.tensor(edge_index.T, dtype=torch.long)\n",
    "edge_attr = torch.from_numpy(edge_attr).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAGE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store data\n",
    "x_SAGE = []\n",
    "\n",
    "# Get dimension of thermal, wind and load\n",
    "num_thermal_features = thermal_gen_features.shape[1]\n",
    "\n",
    "# Empty node feature matrix\n",
    "node_features = np.zeros((buses.shape[0], num_thermal_features+nt*2))\n",
    "\n",
    "# Assign thermal features\n",
    "node_features[thermal_bidx, :num_thermal_features] = thermal_gen_features\n",
    "\n",
    "# Assign wind and load features\n",
    "for i in range(num_samples):\n",
    "    # File path\n",
    "    wind_path = f'../../data/IEEE_Case118/inputs/wind/sample_{i+1}.csv'\n",
    "    load_path = f'../../data/IEEE_Case118/inputs/load/sample_{i+1}.csv'\n",
    "    PG_path = f'./model_evaluation/SAGE/PG_pred_all/pred_{i+1}.csv'\n",
    "\n",
    "    # Read wind and load\n",
    "    try:\n",
    "        wind = pd.read_csv(wind_path, header=None, index_col=None)\n",
    "        load = pd.read_csv(load_path, header=None, index_col=None)\n",
    "        PG = pd.read_csv(PG_path, header=None, index_col=None)\n",
    "    except FileNotFoundError:\n",
    "        print(f'The file sample_{i+1} is not found')\n",
    "        continue\n",
    "\n",
    "    # Assign node features\n",
    "    node_features[wind_bidx, -2*nt:-nt] = wind\n",
    "    node_features[thermal_bidx, -2*nt:-nt] = PG[thermal_bidx]\n",
    "    node_features[load_bidx, -nt:] = load\n",
    "\n",
    "    x_SAGE.append(node_features.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old dataset has been deleted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyDataset(1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the statis of old dataset\n",
    "dir = f'../../train_val_test_dataset/IEEE_Case118/DL-SAGE/processed'\n",
    "if not os.path.exists(dir):\n",
    "    print(f'There is no dataset found!')\n",
    "else:\n",
    "    shutil.rmtree(dir)\n",
    "    print(f'The old dataset has been deleted!')\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(len(x_SAGE)):\n",
    "    X = torch.from_numpy(x_SAGE[i]).float()\n",
    "    Y = torch.from_numpy(y_DL[i]).float()\n",
    "    graph = Data(x=X, y=Y, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    data_list.append(graph)\n",
    "\n",
    "from MyDataset import MyDataset\n",
    "# Not that if there is already saved dataset, this cell won't work\n",
    "# Save train, val and test data\n",
    "root = '../../train_val_test_dataset/IEEE_Case118/DL-SAGE'\n",
    "MyDataset(root=root, data_list=data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store data\n",
    "x_ANN = []\n",
    "\n",
    "# Get dimension of thermal, wind and load\n",
    "num_thermal_features = thermal_gen_features.shape[1]\n",
    "\n",
    "# Empty node feature matrix\n",
    "node_features = np.zeros((buses.shape[0], num_thermal_features+nt*2))\n",
    "\n",
    "# Assign thermal features\n",
    "node_features[thermal_bidx, :num_thermal_features] = thermal_gen_features\n",
    "\n",
    "# Assign wind and load features\n",
    "for i in range(num_samples):\n",
    "    # File path\n",
    "    wind_path = f'../../data/IEEE_Case118/inputs/wind/sample_{i+1}.csv'\n",
    "    load_path = f'../../data/IEEE_Case118/inputs/load/sample_{i+1}.csv'\n",
    "    PG_path = f'./model_evaluation/ANN/PG_pred_all/pred_{i+1}.csv'\n",
    "\n",
    "    # Read wind and load\n",
    "    try:\n",
    "        wind = pd.read_csv(wind_path, header=None, index_col=None)\n",
    "        load = pd.read_csv(load_path, header=None, index_col=None)\n",
    "        PG = pd.read_csv(PG_path, header=None, index_col=None)\n",
    "    except FileNotFoundError:\n",
    "        print(f'The file sample_{i+1} is not found')\n",
    "        continue\n",
    "\n",
    "    # Assign node features\n",
    "    node_features[wind_bidx, -2*nt:-nt] = wind\n",
    "    node_features[thermal_bidx, -2*nt:-nt] = PG[thermal_bidx]\n",
    "    node_features[load_bidx, -nt:] = load\n",
    "\n",
    "    x_ANN.append(node_features.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old dataset has been deleted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyDataset(1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the statis of old dataset\n",
    "dir = f'../../train_val_test_dataset/IEEE_Case118/DL-ANN/processed'\n",
    "if not os.path.exists(dir):\n",
    "    print(f'There is no dataset found!')\n",
    "else:\n",
    "    shutil.rmtree(dir)\n",
    "    print(f'The old dataset has been deleted!')\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(len(x_ANN)):\n",
    "    X = torch.from_numpy(x_ANN[i]).float()\n",
    "    Y = torch.from_numpy(y_DL[i]).float()\n",
    "    graph = Data(x=X, y=Y, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    data_list.append(graph)\n",
    "\n",
    "from MyDataset import MyDataset\n",
    "# Not that if there is already saved dataset, this cell won't work\n",
    "# Save train, val and test data\n",
    "root = '../../train_val_test_dataset/IEEE_Case118/DL-ANN'\n",
    "MyDataset(root=root, data_list=data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store data\n",
    "x_GCN = []\n",
    "\n",
    "# Get dimension of thermal, wind and load\n",
    "num_thermal_features = thermal_gen_features.shape[1]\n",
    "\n",
    "# Empty node feature matrix\n",
    "node_features = np.zeros((buses.shape[0], num_thermal_features+nt*2))\n",
    "\n",
    "# Assign thermal features\n",
    "node_features[thermal_bidx, :num_thermal_features] = thermal_gen_features\n",
    "\n",
    "# Assign wind and load features\n",
    "for i in range(num_samples):\n",
    "    # File path\n",
    "    wind_path = f'../../data/IEEE_Case118/inputs/wind/sample_{i+1}.csv'\n",
    "    load_path = f'../../data/IEEE_Case118/inputs/load/sample_{i+1}.csv'\n",
    "    PG_path = f'./model_evaluation/GCN/PG_pred_all/pred_{i+1}.csv'\n",
    "\n",
    "    # Read wind and load\n",
    "    try:\n",
    "        wind = pd.read_csv(wind_path, header=None, index_col=None)\n",
    "        load = pd.read_csv(load_path, header=None, index_col=None)\n",
    "        PG = pd.read_csv(PG_path, header=None, index_col=None)\n",
    "    except FileNotFoundError:\n",
    "        print(f'The file sample_{i+1} is not found')\n",
    "        continue\n",
    "\n",
    "    # Assign node features\n",
    "    node_features[wind_bidx, -2*nt:-nt] = wind\n",
    "    node_features[thermal_bidx, -2*nt:-nt] = PG[thermal_bidx]\n",
    "    node_features[load_bidx, -nt:] = load\n",
    "\n",
    "    x_GCN.append(node_features.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old dataset has been deleted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyDataset(1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the statis of old dataset\n",
    "dir = f'../../train_val_test_dataset/IEEE_Case118/DL-GCN/processed'\n",
    "if not os.path.exists(dir):\n",
    "    print(f'There is no dataset found!')\n",
    "else:\n",
    "    shutil.rmtree(dir)\n",
    "    print(f'The old dataset has been deleted!')\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(len(x_GCN)):\n",
    "    X = torch.from_numpy(x_GCN[i]).float()\n",
    "    Y = torch.from_numpy(y_DL[i]).float()\n",
    "    graph = Data(x=X, y=Y, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    data_list.append(graph)\n",
    "\n",
    "from MyDataset import MyDataset\n",
    "# Not that if there is already saved dataset, this cell won't work\n",
    "# Save train, val and test data\n",
    "root = '../../train_val_test_dataset/IEEE_Case118/DL-GCN'\n",
    "MyDataset(root=root, data_list=data_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
