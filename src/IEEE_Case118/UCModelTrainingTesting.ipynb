{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root\n",
    "from MyDataset import MyDataset\n",
    "\n",
    "root = '../../train_val_test_dataset/IEEE_Case118/UC'\n",
    "\n",
    "# Load all data with empty input\n",
    "dataset = MyDataset(root=root, data_list=[])\n",
    "\n",
    "# Get train dataset\n",
    "train_size = 700\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "\n",
    "# Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Set hyper-parameters\n",
    "input_dim = 32\n",
    "hidden_dim = 32\n",
    "output_dim = 12\n",
    "\n",
    "# Set device\n",
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNNClassifier import UCANN\n",
    "\n",
    "# Initialize the model\n",
    "model = UCANN(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        loss = F.binary_cross_entropy(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary cross entropy loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/UCANN_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = torch.load('./trained_model/UCANN_model.pt')\n",
    "\n",
    "########################### Testing dataset ###########################\n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "\n",
    "# Create test loader\n",
    "############ Shuffle cannot beb True for testing ##################\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/ANN/UC_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = (pred>0.5).float()\n",
    "        pred = pred.detach().numpy()\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/ANN/UC_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "\n",
    "########################### Complete dataset ###########################\n",
    "# Get test dataset\n",
    "test_dataset = dataset[:]\n",
    "\n",
    "# Create test loader\n",
    "############ Shuffle cannot beb True for testing ##################\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation//ANN/UC_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = (pred>0.5).float()\n",
    "        pred = pred.detach().numpy()\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/ANN/UC_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNNClassifier import UCSAGE\n",
    "\n",
    "# Initialize the model\n",
    "model = UCSAGE(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAGE model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        loss = F.binary_cross_entropy(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary cross entropy loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save SAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/UCSAGE_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAGE model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = torch.load('./trained_model/UCSAGE_model.pt')\n",
    "\n",
    "########################### Testing dataset ###########################\n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "\n",
    "# Create test loader\n",
    "############ Shuffle cannot beb True for testing ##################\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/SAGE/UC_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = (pred>0.5).float()\n",
    "        pred = pred.detach().numpy()\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/SAGE/UC_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "\n",
    "########################### Complete dataset ###########################\n",
    "# Get test dataset\n",
    "test_dataset = dataset[:]\n",
    "\n",
    "# Create test loader\n",
    "############ Shuffle cannot beb True for testing ##################\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation//SAGE/UC_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = (pred>0.5).float()\n",
    "        pred = pred.detach().numpy()\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/SAGE/UC_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNNClassifier import UCGCN\n",
    "\n",
    "# Initialize the model\n",
    "model = UCGCN(input_dim, hidden_dim, output_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        loss = F.binary_cross_entropy(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary cross entropy loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/UCGCN_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCN model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = torch.load('./trained_model/UCGCN_model.pt')\n",
    "\n",
    "########################### Testing dataset ###########################\n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "\n",
    "# Create test loader\n",
    "############ Shuffle cannot beb True for testing ##################\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/GCN/UC_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = (pred>0.5).float()\n",
    "        pred = pred.detach().numpy()\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/GCN/UC_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "\n",
    "########################### Complete dataset ###########################\n",
    "# Get test dataset\n",
    "test_dataset = dataset[:]\n",
    "\n",
    "# Create test loader\n",
    "############ Shuffle cannot beb True for testing ##################\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation//GCN/UC_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = (pred>0.5).float()\n",
    "        pred = pred.detach().numpy()\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/GCN/UC_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
