{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNNPGRegressor import PGSAGE, PGANN, PGGCN\n",
    "from MyDataset import MyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper-parameters\n",
    "input_dim1 = 32\n",
    "input_dim2 = 44\n",
    "hidden_dim1 = 32\n",
    "hidden_dim2 = 32\n",
    "output_dim1 = 32\n",
    "output_dim2 = 12\n",
    "\n",
    "# Set device\n",
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../train_val_test_dataset/IEEE_Case118/PG-SAGE'\n",
    "\n",
    "# Load all data with empty input\n",
    "dataset = MyDataset(root=root, data_list=[])\n",
    "\n",
    "# Get train dataset\n",
    "train_size = 700\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "\n",
    "# Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = PGSAGE(input_dim1, input_dim2, hidden_dim1, hidden_dim2, output_dim1, output_dim2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAGE model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        loss = F.mse_loss(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save SAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/PGSAGE_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAGE model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './trained_model/PGSAGE_model.pt'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Testing dataset \n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/SAGE/PG_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<30] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/SAGE/PG_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "# Complete dataset\n",
    "test_dataset = dataset[:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/SAGE/PG_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<30] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/SAGE/PG_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../train_val_test_dataset/IEEE_Case118/PG-ANN'\n",
    "\n",
    "# Load all data with empty input\n",
    "dataset = MyDataset(root=root, data_list=[])\n",
    "\n",
    "# Get train dataset\n",
    "train_size = 700\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "\n",
    "# Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = PGANN(input_dim1, input_dim2, hidden_dim1, hidden_dim2, output_dim1, output_dim2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        loss = F.mse_loss(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/PGANN_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './trained_model/PGANN_model.pt'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Testing dataset \n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/ANN/PG_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<30] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/ANN/PG_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "# Complete dataset\n",
    "test_dataset = dataset[:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/ANN/PG_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<30] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/ANN/PG_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../train_val_test_dataset/IEEE_Case118/PG-GCN'\n",
    "\n",
    "# Load all data with empty input\n",
    "dataset = MyDataset(root=root, data_list=[])\n",
    "\n",
    "# Get train dataset\n",
    "train_size = 700\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "\n",
    "# Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = PGGCN(input_dim1, input_dim2, hidden_dim1, hidden_dim2, output_dim1, output_dim2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        loss = F.mse_loss(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/PGGCN_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCN model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './trained_model/PGGCN_model.pt'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Testing dataset \n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/GCN/PG_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<30] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/GCN/PG_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "# Complete dataset\n",
    "test_dataset = dataset[:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/GCN/PG_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<30] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/GCN/PG_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
