{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNNPGRegressor import PGSAGE, PGANN, PGGCN\n",
    "from MyDataset import MyDataset\n",
    "from CustomLoss import CustomLoss\n",
    "\n",
    "custom_loss = CustomLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper-parameters\n",
    "input_dim1 = 32\n",
    "input_dim2 = 44\n",
    "hidden_dim1 = 32\n",
    "hidden_dim2 = 128\n",
    "output_dim1 = 32\n",
    "output_dim2 = 12\n",
    "\n",
    "# Set device\n",
    "# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PGANN(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (ann): Sequential(\n",
       "    (0): Linear(in_features=44, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '../../train_val_test_dataset/IEEE_Case118/PG-ANN'\n",
    "\n",
    "# Load all data with empty input\n",
    "dataset = MyDataset(root=root, data_list=[])\n",
    "\n",
    "# Get train dataset\n",
    "train_size = 700\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "\n",
    "# Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = PGANN(input_dim1, input_dim2, hidden_dim1, hidden_dim2, output_dim1, output_dim2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set number of epochs\n",
    "epochs = 2\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        # loss = F.mse_loss(y_pred, loader.y)\n",
    "        loss = custom_loss(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/PGANN_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(ground_true)\u001b[39m.\u001b[39mto_csv(file_path, columns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, index\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Get prediction\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m pred \u001b[39m=\u001b[39m model(loader\u001b[39m.\u001b[39;49mx, loader\u001b[39m.\u001b[39;49medge_index)\n\u001b[0;32m     22\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     24\u001b[0m \u001b[39m############ Add postprocessing ##############\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhay109\\.conda\\envs\\PyG-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\zhay109\\Documents\\yadong_zhang\\GNN_SCUC\\src\\IEEE_Case118\\GNNPGRegressor.py:43\u001b[0m, in \u001b[0;36mPGANN.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[0;32m     42\u001b[0m     \u001b[39m# Encoder\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     temp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x[:, :\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_dim1])\n\u001b[0;32m     44\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([temp, x[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dim1:]], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     46\u001b[0m     \u001b[39m# ANN layers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhay109\\.conda\\envs\\PyG-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\zhay109\\.conda\\envs\\PyG-gpu\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\zhay109\\.conda\\envs\\PyG-gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\zhay109\\.conda\\envs\\PyG-gpu\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "model_path = './trained_model/PGANN_model.pt'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Testing dataset \n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/ANN/PG_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<25] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/ANN/PG_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "# Complete dataset\n",
    "test_dataset = dataset[:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/ANN/PG_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<25] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/ANN/PG_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../train_val_test_dataset/IEEE_Case118/PG-SAGE'\n",
    "\n",
    "# Load all data with empty input\n",
    "dataset = MyDataset(root=root, data_list=[])\n",
    "\n",
    "# Get train dataset\n",
    "train_size = 700\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "\n",
    "# Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = PGSAGE(input_dim1, input_dim2, hidden_dim1, hidden_dim2, output_dim1, output_dim2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAGE model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        # loss = F.mse_loss(y_pred, loader.y)\n",
    "        loss = custom_loss(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save SAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/PGSAGE_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAGE model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './trained_model/PGSAGE_model.pt'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Testing dataset \n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/SAGE/PG_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<25] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/SAGE/PG_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "# Complete dataset\n",
    "test_dataset = dataset[:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/SAGE/PG_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<25] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/SAGE/PG_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../../train_val_test_dataset/IEEE_Case118/PG-GCN'\n",
    "\n",
    "# Load all data with empty input\n",
    "dataset = MyDataset(root=root, data_list=[])\n",
    "\n",
    "# Get train dataset\n",
    "train_size = 700\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "\n",
    "# Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = PGGCN(input_dim1, input_dim2, hidden_dim1, hidden_dim2, output_dim1, output_dim2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of epochs\n",
    "epochs = 500\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Model training and validation\n",
    "epoch_loss = []\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    for loader in train_loader:\n",
    "        loader.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(loader.x, loader.edge_index)\n",
    "\n",
    "        # loss = F.mse_loss(y_pred, loader.y)\n",
    "        loss = custom_loss(y_pred, loader.y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "    epoch_loss.append(np.mean(batch_loss))\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = (end_time - start_time)/60\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(epoch_loss)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.title(f'Training time: {training_time:.2f}')\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_model/PGGCN_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCN model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './trained_model/PGGCN_model.pt'\n",
    "model = torch.load(model_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Testing dataset \n",
    "# Get test dataset\n",
    "test_size = 200\n",
    "test_dataset = dataset[-test_size:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/GCN/PG_true/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<25] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/GCN/PG_pred/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "\n",
    "# Complete dataset\n",
    "test_dataset = dataset[:]\n",
    "############ Shuffle cannot be true for testing data ##############\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i, loader in enumerate(test_loader):\n",
    "        # Get ground true\n",
    "        ground_true = loader.y.detach().numpy()\n",
    "        # Save ground true\n",
    "        file_path = f'./model_evaluation/GCN/PG_true_all/true_{i+1}.csv'\n",
    "        pd.DataFrame(ground_true).to_csv(file_path, columns=None, index=None, header=None)\n",
    "\n",
    "        # Get prediction\n",
    "        pred = model(loader.x, loader.edge_index)\n",
    "        pred = pred.detach().numpy()\n",
    "\n",
    "        ############ Add postprocessing ##############\n",
    "        pred[pred<25] = 0\n",
    "\n",
    "        # Save prediction\n",
    "        file_path = f'./model_evaluation/GCN/PG_pred_all/pred_{i+1}.csv'\n",
    "        pd.DataFrame(pred).to_csv(file_path, columns=None, index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
